#!/usr/bin/env python3
"""
API è¯¦ç»†è¯Šæ–­è„šæœ¬
ç”¨äºè°ƒè¯•500é”™è¯¯çš„å…·ä½“åŸå› 
"""

import requests
import json
import traceback

def test_single_request_debug():
    """æµ‹è¯•å•ä¸ªè¯·æ±‚å¹¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯"""
    
    base_url = "http://localhost:8000"
    
    # ç®€å•çš„æµ‹è¯•ç”¨ä¾‹
    test_params = {
        "dataset": "Cora",
        "model": "graphsage", 
        "task": "node",
        "node_id": 0,
        "timeout": 30
    }
    
    print("ğŸ” API è¯¦ç»†è¯Šæ–­")
    print("=" * 50)
    
    try:
        print("1. å¥åº·æ£€æŸ¥...")
        health_response = requests.get(f"{base_url}/api/v1/health", timeout=10)
        print(f"   çŠ¶æ€ç : {health_response.status_code}")
        if health_response.status_code == 200:
            health_data = health_response.json()
            print(f"   è®¾å¤‡: {health_data.get('device')}")
            print(f"   CUDAå¯ç”¨: {health_data.get('cuda_available')}")
            print(f"   å·²åŠ è½½æ¨¡å‹: {health_data.get('loaded_models')}")
        else:
            print(f"   å¥åº·æ£€æŸ¥å¤±è´¥: {health_response.text}")
            return
            
        print("\n2. è·å–å¯ç”¨æ¨¡å‹...")
        models_response = requests.get(f"{base_url}/api/v1/models", timeout=10)
        print(f"   çŠ¶æ€ç : {models_response.status_code}")
        if models_response.status_code == 200:
            models_data = models_response.json()
            print(f"   æ”¯æŒçš„æ•°æ®é›†: {models_data.get('supported_datasets', [])}")
            print(f"   æ”¯æŒçš„æ¨¡å‹: {models_data.get('supported_model_types', [])}")
            print(f"   å·²åŠ è½½æ¨¡å‹: {models_data.get('loaded_models', [])}")
        else:
            print(f"   è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {models_response.text}")
            
        print(f"\n3. æµ‹è¯•å•èŠ‚ç‚¹è§£é‡Š...")
        print(f"   å‚æ•°: {test_params}")
        
        # å‘é€è¯·æ±‚å¹¶è·å–è¯¦ç»†å“åº”
        response = requests.post(
            f"{base_url}/api/v1/explain/single",
            params=test_params,
            timeout=60
        )
        
        print(f"   çŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å¤´: {dict(response.headers)}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"   âœ… æˆåŠŸ!")
            print(f"   èŠ‚ç‚¹ID: {result.get('node_id')}")
            print(f"   é‡è¦æ€§: {result.get('importance')}")
            print(f"   å¤„ç†æ—¶é—´: {result.get('processing_time')}ç§’")
        else:
            print(f"   âŒ å¤±è´¥!")
            print(f"   å“åº”å†…å®¹: {response.text}")
            
            # å°è¯•è§£æJSONé”™è¯¯
            try:
                error_data = response.json()
                print(f"   é”™è¯¯è¯¦æƒ…: {error_data.get('detail', 'æœªçŸ¥é”™è¯¯')}")
            except:
                print("   æ— æ³•è§£æé”™è¯¯JSON")
                
    except requests.exceptions.Timeout:
        print("   â° è¯·æ±‚è¶…æ—¶")
    except requests.exceptions.ConnectionError:
        print("   ğŸ”Œ è¿æ¥å¤±è´¥ï¼Œè¯·ç¡®è®¤APIæœåŠ¡å·²å¯åŠ¨")
    except Exception as e:
        print(f"   âŒ å¼‚å¸¸: {e}")
        traceback.print_exc()

def test_import_dependencies():
    """æµ‹è¯•é¡¹ç›®ä¾èµ–æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¼å…¥"""
    
    print("\nğŸ”— æµ‹è¯•é¡¹ç›®ä¾èµ–å¯¼å…¥")
    print("=" * 50)
    
    dependencies = [
        ("torch", "import torch"),
        ("numpy", "import numpy as np"),
        ("networkx", "import networkx as nx"),
        ("fastapi", "from fastapi import FastAPI"),
        ("pydantic", "from pydantic import BaseModel"),
        ("explainer.args", "import explainer.args as args"),
        ("explainer.utils", "import explainer.utils as ut"),
        ("explainer.unrexplainer", "import explainer.unrexplainer as unr")
    ]
    
    for name, import_cmd in dependencies:
        try:
            exec(import_cmd)
            print(f"   âœ… {name}: å¯¼å…¥æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ {name}: å¯¼å…¥å¤±è´¥ - {e}")

def test_direct_model_load():
    """ç›´æ¥æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    
    print("\nğŸ¤– æµ‹è¯•æ¨¡å‹åŠ è½½")
    print("=" * 50)
    
    try:
        # ç›´æ¥å¯¼å…¥å’Œæµ‹è¯•æ¨¡å‹åŠ è½½ç›¸å…³æ¨¡å—
        import explainer.args as args
        import explainer.utils as ut
        
        print("   âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºå‚æ•°
        import argparse
        parser = argparse.ArgumentParser()
        parser.add_argument('--dataset', default='Cora')
        parser.add_argument('--model', default='graphsage')
        parser.add_argument('--task', default='node')
        parser.add_argument('--gpu', default='0')
        parser.add_argument('--hidden_dim', default=128, type=int)
        
        test_args = parser.parse_args([])
        print(f"   âœ… å‚æ•°åˆ›å»ºæˆåŠŸ: {test_args.dataset}, {test_args.model}, {test_args.task}")
        
        # æµ‹è¯•æ•°æ®é›†åŠ è½½
        print("   ğŸ”„ å°è¯•åŠ è½½æ•°æ®é›†...")
        data, G = ut.load_dataset(test_args)
        print(f"   âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(G.nodes())} èŠ‚ç‚¹, {len(G.edges())} è¾¹")
        
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("   ğŸ”„ å°è¯•åŠ è½½æ¨¡å‹...")
        import torch
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model, z = ut.load_model(test_args, data, device)
        print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: åµŒå…¥ç»´åº¦ {z.shape}")
        
    except Exception as e:
        print(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()

def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    
    print("\nğŸ“ æ£€æŸ¥æ•°æ®æ–‡ä»¶")
    print("=" * 50)
    
    import os
    
    # æ£€æŸ¥å¸¸è§çš„æ•°æ®ç›®å½•
    data_dirs = [
        'data',
        'dataset', 
        'datasets',
        './data',
        './dataset',
        './datasets'
    ]
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            print(f"   âœ… æ‰¾åˆ°æ•°æ®ç›®å½•: {data_dir}")
            try:
                files = os.listdir(data_dir)
                print(f"      åŒ…å«æ–‡ä»¶: {files[:5]}{'...' if len(files) > 5 else ''}")
            except:
                print(f"      æ— æ³•è¯»å–ç›®å½•å†…å®¹")
        else:
            print(f"   âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # æ£€æŸ¥æ¨¡å‹ç›®å½•
    model_dirs = [
        'model',
        'models', 
        'checkpoints',
        './model',
        './models',
        './checkpoints'
    ]
    
    for model_dir in model_dirs:
        if os.path.exists(model_dir):
            print(f"   âœ… æ‰¾åˆ°æ¨¡å‹ç›®å½•: {model_dir}")
            try:
                files = os.listdir(model_dir)
                print(f"      åŒ…å«æ–‡ä»¶: {files[:5]}{'...' if len(files) > 5 else ''}")
            except:
                print(f"      æ— æ³•è¯»å–ç›®å½•å†…å®¹")
        else:
            print(f"   âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")

if __name__ == "__main__":
    print("ğŸš¨ UNR-Explainer API è¯Šæ–­å·¥å…·")
    print("ğŸ”§ ç”¨äºè°ƒè¯•500é”™è¯¯é—®é¢˜")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•ä¾èµ–å¯¼å…¥
        test_import_dependencies()
        
        # 2. æ£€æŸ¥æ•°æ®æ–‡ä»¶
        check_data_files()
        
        # 3. ç›´æ¥æµ‹è¯•æ¨¡å‹åŠ è½½
        test_direct_model_load()
        
        # 4. æµ‹è¯•APIè¯·æ±‚
        test_single_request_debug()
        
        print("\n" + "=" * 60)
        print("ğŸ¯ è¯Šæ–­å®Œæˆ!")
        print("è¯·æŸ¥çœ‹ä¸Šè¿°è¾“å‡ºï¼Œæ‰¾åˆ°å¤±è´¥çš„ç¯èŠ‚è¿›è¡Œä¿®å¤ã€‚")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­è¯Šæ–­")
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        traceback.print_exc() 