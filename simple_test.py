#!/usr/bin/env python3
"""
ç®€åŒ–çš„APIåŠŸèƒ½æµ‹è¯•
"""

import sys
sys.path.append('.')

import torch
import argparse
import explainer.args as args
import explainer.utils as ut
import explainer.unrexplainer as unr

def test_direct_explanation():
    """ç›´æ¥æµ‹è¯•è§£é‡ŠåŠŸèƒ½ï¼Œä¸é€šè¿‡API"""
    
    print("ğŸ§ª ç›´æ¥æµ‹è¯•è§£é‡ŠåŠŸèƒ½")
    print("=" * 50)
    
    try:
        # æµ‹è¯•å‚æ•°
        parser = argparse.ArgumentParser()
        
        # åŸºæœ¬å‚æ•° - ä½¿ç”¨å·²çŸ¥å­˜åœ¨çš„æ¨¡å‹
        parser.add_argument('--dataset', default='syn1')
        parser.add_argument('--model', default='graphsage')
        parser.add_argument('--task', default='node')
        parser.add_argument('--gpu', default='0')
        parser.add_argument('--hidden_dim', default=128, type=int)
        parser.add_argument('--neighbors_cnt', default=10, type=int)
        parser.add_argument('--num_layers', default=2, type=int)
        
        # è§£é‡Šå™¨å‚æ•°
        parser.add_argument('--samples', default=10, type=int)  # å‡å°‘æ ·æœ¬æ•°ä»¥åŠ å¿«æµ‹è¯•
        parser.add_argument('--mcts_simulations', default=50, type=int)  # å‡å°‘æ¨¡æ‹Ÿæ¬¡æ•°
        parser.add_argument('--maxiter', default=20, type=int)  # å‡å°‘æœ€å¤§è¿­ä»£æ¬¡æ•°
        parser.add_argument('--max_depth', default=2, type=int)  # å‡å°‘æœ€å¤§æ·±åº¦
        parser.add_argument('--c_puct', default=5.0, type=float)
        parser.add_argument('--restart', default=0.1, type=float)
        parser.add_argument('--expansion_num', default=3, type=int)
        parser.add_argument('--c1', default=1.0, type=float)
        
        test_args = parser.parse_args([])
        
        print(f"âœ… å‚æ•°: {test_args.dataset}, {test_args.model}, {test_args.task}")
        
        # è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"âœ… è®¾å¤‡: {device}")
        
        # åŠ è½½æ•°æ®é›†
        print("ğŸ”„ åŠ è½½æ•°æ®é›†...")
        data, G = ut.load_dataset(test_args)
        print(f"âœ… æ•°æ®é›†: {len(G.nodes())} èŠ‚ç‚¹, {len(G.edges())} è¾¹")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ”„ åŠ è½½æ¨¡å‹...")
        model, z = ut.load_model(test_args, data, device)
        print(f"âœ… æ¨¡å‹: åµŒå…¥ç»´åº¦ {z.shape}")
        
        # å¤„ç†åµŒå…¥ä¿¡æ¯
        print("ğŸ”„ å¤„ç†åµŒå…¥ä¿¡æ¯...")
        emb_info = ut.emb_dist_rank(z, test_args.neighbors_cnt)
        print(f"âœ… åµŒå…¥ä¿¡æ¯å¤„ç†å®Œæˆ")
        
        # æµ‹è¯•è§£é‡Š
        node_id = 0
        print(f"ğŸ”„ è§£é‡ŠèŠ‚ç‚¹ {node_id}...")
        
        subgraph, importance_score = unr.explainer(
            test_args, model, G, data, emb_info, node_id, device
        )
        
        print(f"âœ… è§£é‡Šå®Œæˆ!")
        print(f"   èŠ‚ç‚¹ID: {node_id}")
        print(f"   é‡è¦æ€§åˆ†æ•°: {importance_score}")
        print(f"   å­å›¾èŠ‚ç‚¹æ•°: {subgraph.number_of_nodes()}")
        print(f"   å­å›¾è¾¹æ•°: {subgraph.number_of_edges()}")
        print(f"   å­å›¾èŠ‚ç‚¹: {list(subgraph.nodes())}")
        
        # æµ‹è¯•å¦ä¸€ä¸ªèŠ‚ç‚¹
        node_id = 1
        print(f"\nğŸ”„ è§£é‡ŠèŠ‚ç‚¹ {node_id}...")
        
        subgraph2, importance_score2 = unr.explainer(
            test_args, model, G, data, emb_info, node_id, device
        )
        
        print(f"âœ… è§£é‡Šå®Œæˆ!")
        print(f"   èŠ‚ç‚¹ID: {node_id}")
        print(f"   é‡è¦æ€§åˆ†æ•°: {importance_score2}")
        print(f"   å­å›¾èŠ‚ç‚¹æ•°: {subgraph2.number_of_nodes()}")
        print(f"   å­å›¾è¾¹æ•°: {subgraph2.number_of_edges()}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_multiple_datasets():
    """æµ‹è¯•å¤šä¸ªæ•°æ®é›†"""
    
    print("\nğŸ§ª æµ‹è¯•å¤šä¸ªæ•°æ®é›†")
    print("=" * 50)
    
    # æ ¹æ®å®é™…å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ç»„åˆ
    test_cases = [
        {'dataset': 'syn1', 'model': 'graphsage', 'task': 'node'},
        {'dataset': 'syn3', 'model': 'graphsage', 'task': 'node'},
        {'dataset': 'syn4', 'model': 'graphsage', 'task': 'node'},
        {'dataset': 'PubMed', 'model': 'dgi', 'task': 'node'},
        {'dataset': 'Cora', 'model': 'graphsage', 'task': 'link'},
    ]
    
    success_count = 0
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n--- æµ‹è¯•ç”¨ä¾‹ {i}: {case['dataset']} + {case['model']} + {case['task']} ---")
        
        try:
            # åˆ›å»ºå‚æ•°
            parser = argparse.ArgumentParser()
            parser.add_argument('--dataset', default=case['dataset'])
            parser.add_argument('--model', default=case['model'])
            parser.add_argument('--task', default=case['task'])
            parser.add_argument('--gpu', default='0')
            parser.add_argument('--hidden_dim', default=128, type=int)
            parser.add_argument('--neighbors_cnt', default=10, type=int)
            parser.add_argument('--num_layers', default=2, type=int)
            parser.add_argument('--samples', default=5, type=int)
            parser.add_argument('--mcts_simulations', default=30, type=int)
            parser.add_argument('--maxiter', default=10, type=int)
            parser.add_argument('--max_depth', default=2, type=int)
            parser.add_argument('--c_puct', default=5.0, type=float)
            parser.add_argument('--restart', default=0.1, type=float)
            parser.add_argument('--expansion_num', default=3, type=int)
            parser.add_argument('--c1', default=1.0, type=float)
            
            test_args = parser.parse_args([])
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # åŠ è½½æ•°æ®å’Œæ¨¡å‹
            data, G = ut.load_dataset(test_args)
            model, z = ut.load_model(test_args, data, device)
            
            if case['dataset'].upper() == 'DBLP':
                emb_info = ut.emb_dist_rank_dblp(z, test_args.neighbors_cnt, True)
            else:
                emb_info = ut.emb_dist_rank(z, test_args.neighbors_cnt)
            
            # æµ‹è¯•è§£é‡Š
            node_id = 0
            subgraph, importance_score = unr.explainer(
                test_args, model, G, data, emb_info, node_id, device
            )
            
            print(f"   âœ… æˆåŠŸ! é‡è¦æ€§: {importance_score:.4f}, å­å›¾: {subgraph.number_of_nodes()} èŠ‚ç‚¹")
            success_count += 1
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
    
    print(f"\nğŸ¯ æ€»ç»“: {success_count}/{len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹æˆåŠŸ")
    return success_count == len(test_cases)

if __name__ == "__main__":
    print("ğŸš€ UNR-Explainer åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1ï¼šåŸºæœ¬åŠŸèƒ½
    success1 = test_direct_explanation()
    
    # æµ‹è¯•2ï¼šå¤šæ•°æ®é›†
    success2 = test_multiple_datasets()
    
    print(f"\n{'='*60}")
    if success1 and success2:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼APIåŠŸèƒ½æ­£å¸¸")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    print(f"{'='*60}") 