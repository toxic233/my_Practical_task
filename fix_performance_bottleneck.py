#!/usr/bin/env python3
"""
ä¿®å¤æ€§èƒ½ç“¶é¢ˆé—®é¢˜

é—®é¢˜ï¼šperturb_embå‡½æ•°åœ¨DBLPæ•°æ®é›†å¤„ç†ä¸­æ¯æ¬¡éƒ½é‡æ–°åŠ è½½æ•°æ®ï¼Œé€ æˆä¸¥é‡æ€§èƒ½ç“¶é¢ˆ
è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤åŠ è½½
"""

import sys
import os

def fix_dblp_loading_bottleneck():
    """
    ä¿®å¤DBLPæ•°æ®é‡å¤åŠ è½½çš„æ€§èƒ½ç“¶é¢ˆ
    """
    print("=" * 60)
    print("ä¿®å¤DBLPæ•°æ®é‡å¤åŠ è½½çš„æ€§èƒ½ç“¶é¢ˆ")
    print("=" * 60)
    
    # è¯»å–åŸæ–‡ä»¶
    utils_file = 'explainer/utils.py'
    
    with open(utils_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å®šä½éœ€è¦æ›¿æ¢çš„éƒ¨åˆ†
    old_section = '''            else:  # DBLP
                # DBLPæ•°æ®é›†æœ‰4ç§èŠ‚ç‚¹ç±»å‹
                num_author = 4057
                num_paper = 14328
                num_term = 7723
                num_conf = 20
                
                # ä»dataset.magnn_utils.dataå¯¼å…¥load_DBLP_dataå‡½æ•°
                from dataset.magnn_utils.data import load_DBLP_data
                
                # åŠ è½½çœŸå®çš„DBLPæ•°æ®ï¼Œè·å–æ­£ç¡®ç»´åº¦çš„ç‰¹å¾
                #print("åŠ è½½DBLPæ•°æ®ä»¥è·å–æ­£ç¡®ç»´åº¦çš„ç‰¹å¾...")
                adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_DBLP_data()
                
                # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾å­—å…¸ï¼Œä½¿ç”¨æ­£ç¡®ç»´åº¦çš„ç‰¹å¾
                features_0 = torch.FloatTensor(features_list[0])  # author
                features_1 = torch.FloatTensor(features_list[1])  # paper
                features_2 = torch.FloatTensor(features_list[2])  # term
                features_3 = torch.FloatTensor(features_list[3])  # conference
                
                node_features_dict = {
                    'author': features_0,
                    'paper': features_1,
                    'term': features_2,
                    'conference': features_3
                }'''
    
    new_section = '''            else:  # DBLP
                # DBLPæ•°æ®é›†æœ‰4ç§èŠ‚ç‚¹ç±»å‹
                num_author = 4057
                num_paper = 14328
                num_term = 7723
                num_conf = 20
                
                # ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾ï¼Œé¿å…é‡å¤åŠ è½½æ•°æ®
                if not hasattr(perturb_emb, 'cached_dblp_features'):
                    from dataset.magnn_utils.data import load_DBLP_data
                    print("ğŸ”„ é¦–æ¬¡åŠ è½½DBLPæ•°æ®ä»¥è·å–æ­£ç¡®ç»´åº¦çš„ç‰¹å¾...")
                    adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_DBLP_data()
                    
                    # ç¼“å­˜ç‰¹å¾æ•°æ®
                    perturb_emb.cached_dblp_features = {
                        'author': torch.FloatTensor(features_list[0]),
                        'paper': torch.FloatTensor(features_list[1]),
                        'term': torch.FloatTensor(features_list[2]),
                        'conference': torch.FloatTensor(features_list[3])
                    }
                    print("âœ… DBLPç‰¹å¾æ•°æ®å·²ç¼“å­˜ï¼Œåç»­è°ƒç”¨å°†ç›´æ¥ä½¿ç”¨ç¼“å­˜")
                
                # ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾
                node_features_dict = perturb_emb.cached_dblp_features'''
    
    # æ£€æŸ¥å¹¶æ›¿æ¢
    if old_section in content:
        content = content.replace(old_section, new_section)
        print("âœ… æ‰¾åˆ°å¹¶æ›¿æ¢äº†DBLPæ•°æ®åŠ è½½éƒ¨åˆ†")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„DBLPæ•°æ®åŠ è½½éƒ¨åˆ†ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…...")
        
        # å°è¯•æ›´ç®€å•çš„æ›¿æ¢
        if "from dataset.magnn_utils.data import load_DBLP_data" in content:
            # å…ˆæ·»åŠ ç¼“å­˜æ£€æŸ¥
            content = content.replace(
                "# ä»dataset.magnn_utils.dataå¯¼å…¥load_DBLP_dataå‡½æ•°\n                from dataset.magnn_utils.data import load_DBLP_data",
                '''# ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾ï¼Œé¿å…é‡å¤åŠ è½½æ•°æ®
                if not hasattr(perturb_emb, 'cached_dblp_features'):
                    from dataset.magnn_utils.data import load_DBLP_data'''
            )
            
            # æ›¿æ¢æ•°æ®åŠ è½½éƒ¨åˆ†
            content = content.replace(
                "adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_DBLP_data()",
                '''print("ğŸ”„ é¦–æ¬¡åŠ è½½DBLPæ•°æ®ä»¥è·å–æ­£ç¡®ç»´åº¦çš„ç‰¹å¾...")
                    adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_DBLP_data()
                    
                    # ç¼“å­˜ç‰¹å¾æ•°æ®
                    perturb_emb.cached_dblp_features = {
                        'author': torch.FloatTensor(features_list[0]),
                        'paper': torch.FloatTensor(features_list[1]),
                        'term': torch.FloatTensor(features_list[2]),
                        'conference': torch.FloatTensor(features_list[3])
                    }
                    print("âœ… DBLPç‰¹å¾æ•°æ®å·²ç¼“å­˜ï¼Œåç»­è°ƒç”¨å°†ç›´æ¥ä½¿ç”¨ç¼“å­˜")
                
                # ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾
                node_features_dict = perturb_emb.cached_dblp_features
                
                # ä¸ºäº†å…¼å®¹æ€§ï¼Œä»ç„¶è®¾ç½®åŸå§‹å˜é‡ï¼ˆä½†ä¸ä¼šé‡å¤æ‰§è¡Œï¼‰
                if 'features_list' not in locals():
                    features_list = [
                        node_features_dict['author'].numpy(),
                        node_features_dict['paper'].numpy(),
                        node_features_dict['term'].numpy(),
                        node_features_dict['conference'].numpy()
                    ]'''
            )
            
            # åˆ é™¤åŸæ¥çš„ç‰¹å¾åˆ›å»ºä»£ç 
            old_feature_creation = '''                # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾å­—å…¸ï¼Œä½¿ç”¨æ­£ç¡®ç»´åº¦çš„ç‰¹å¾
                features_0 = torch.FloatTensor(features_list[0])  # author
                features_1 = torch.FloatTensor(features_list[1])  # paper
                features_2 = torch.FloatTensor(features_list[2])  # term
                features_3 = torch.FloatTensor(features_list[3])  # conference
                
                node_features_dict = {
                    'author': features_0,
                    'paper': features_1,
                    'term': features_2,
                    'conference': features_3
                }'''
            
            if old_feature_creation in content:
                content = content.replace(old_feature_creation, "")
                print("âœ… åˆ é™¤äº†åŸå§‹çš„ç‰¹å¾åˆ›å»ºä»£ç ")
        
        print("âœ… å®Œæˆäº†éƒ¨åˆ†æ›¿æ¢")
    
    # å†™å›æ–‡ä»¶
    with open(utils_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("\n" + "=" * 60)
    print("æ€§èƒ½ç“¶é¢ˆä¿®å¤æ€»ç»“")
    print("=" * 60)
    print("ğŸ”§ ä¿®å¤çš„é—®é¢˜:")
    print("   1. æ¯æ¬¡MCTSè¿­ä»£éƒ½é‡æ–°åŠ è½½DBLPæ•°æ®é›†")
    print("   2. é€ æˆå¤§é‡ä¸å¿…è¦çš„I/Oå’Œå†…å­˜æ“ä½œ")
    print("   3. å¯¼è‡´ç¨‹åºé•¿æ—¶é—´å¡é¡¿å¹¶è¢«killed")
    
    print("\nâœ… è§£å†³æ–¹æ¡ˆ:")
    print("   1. å®ç°äº†æ•°æ®ç¼“å­˜æœºåˆ¶")
    print("   2. é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½å¹¶ç¼“å­˜ç‰¹å¾æ•°æ®")
    print("   3. åç»­è°ƒç”¨ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œé¿å…é‡å¤åŠ è½½")
    print("   4. æ˜¾è‘—å‡å°‘I/Oæ“ä½œå’Œå†…å­˜åˆ†é…")
    
    print("\nğŸš€ é¢„æœŸæ•ˆæœ:")
    print("   - å¤§å¹…æå‡MCTSè¿­ä»£é€Ÿåº¦")
    print("   - é¿å…ç¨‹åºè¢«killedçš„é—®é¢˜")
    print("   - ä¿æŒåŠŸèƒ½çš„æ­£ç¡®æ€§")
    print("   - å‡å°‘å†…å­˜å ç”¨")

if __name__ == "__main__":
    fix_dblp_loading_bottleneck() 